# Augmentation ì‚¬ìš©ë²•

## ðŸ¤— [EDA](#eda)  
## ðŸ¤— [AEDA](#aeda)
## ðŸ¤— [Back Translation](back_trans/README.md)


## EDA  
### Random swap, Random Delete
- [eda.py](./eda.py)ë¥¼ [train.py](../train.py)ì™€ ê°™ì€ í´ë”ì— ë„£ì–´ì£¼ì„¸ìš”
- [train.py](../train.py) ì— importë¥¼ í•´ì£¼ì„¸ìš”  
```py
from eda import *
```
- [train.py](../train.py) ì— eda í•¨ìˆ˜ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤. 
```python
   def eda(dataset):
       dataset = calculate_idx(dataset)
       dataset = random_delete(dataset,0.3)
       return dataset
```
- pëŠ” augmentationì´ ì¼ì–´ë‚  í™•ë¥ ìž…ë‹ˆë‹¤.  
- swapì´ë‚˜ deleteí•˜ê¸°ì „ì— calculate_idxí•¨ìˆ˜ë¥¼ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤.  
- `train_dataset` ì„ ì–¸ ì´í›„ì— `augmented_train_dataset` ì„ ì„ ì–¸í•´ì„œ train_dataset ëŒ€ì‹ ì— ì‚¬ìš©í•˜ì‹œë©´ ë©ë‹ˆë‹¤.
```python
augmented_train_dataset = easy_data_augmentation(train_dataset)
```


---
## AEDA
- [aeda.py](./aeda.py) ë¥¼ [train.py](../train.py)ì™€ ê°™ì€ í´ë”ì— ë„£ì–´ì£¼ì„¸ìš”
- [train.py](../train.py) ì— importë¥¼ í•´ì£¼ì„¸ìš” 
```py
from aeda import *
```
- [train.py](../train.py) ì˜ argparseì— ìœ„ ì½”ë“œë¥¼ ì¶”ê°€í•˜ë©´ aedaë¡œ ë¬¸ìž¥ì„ ëª‡ë°°ë¡œ ëŠ˜ë¦´ ê²ƒì¸ì§€ ì„¤ì • ê°€ëŠ¥í•©ë‹ˆë‹¤.
```py
parser.add_argument("--aeda", type=int, default=2, help="aeda num (default: 2")
``` 
- `train_label` ì„ ì–¸ ì´í›„ì— aeda ì½”ë“œë¥¼ ì¶”ê°€í•´ ì£¼ë©´ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.
```py
train_label = preprocess.label_to_num(train_dataset["label"].values)
val_label = preprocess.label_to_num(val_dataset["label"].values)

# data augmentation (AEDA)
if args.aeda > 1:
   train_dataset, train_label = start_aeda(train_dataset, train_label, args.aeda)
```


## Random masking
```python
train.py

tokenized_train, token_size= preprocess.tokenized_dataset(train_dataset, tokenizer, mask_flag=True)
tokenized_val, _= preprocess.tokenized_dataset(val_dataset, tokenizer, mask_flag=True)
```
